October 9 2024 Notes
=
Midterm Prep and Review
-
---
__Things to remember:__
Bolded things are most important
* Stacks and Queues 
-Remember stack is LIFO and Queue is FIFO

* How to get from a graph to 
adjacency matrix and adjacency list
-Adjacency Matrix $\rightarrow$ really simple just a matrix with the x axis being every value in the graph and the y axis also being every value, every time that the value on the y axis is connected to the value in the x axis the number 1 is put into the matrix, otherwise 0 is in that place
-Adjacency List $\rightarrow$ A list of every node in the graph, when that node is connected to another it is indicated with an arrow, when it is connected to multiple, multiple arrows are used in a row 
EX: 1 is connected to both 2 and 3: 1 $\rightarrow$ 2 $\rightarrow$ 3

* How to select basic operations when analyzing time complexity 
-__It is the operation that is executed more frequently & depends on the input size__

* How $\theta$, O and Omega notation work and be able to express them 
-$\theta$ is the normal running time and is the most accurate time complexity statement
-O is the worst case time complexity 
-Omega is the best case time complexity

* How to simplify the efficiency function of an algorithm 
-Remember things like $n^2+12$ $\epsilon$ $\theta$($n^2$)

* How to solve the time complexity through backwards substitution 
-Easier than it sounds, pretty much add the recurrence relation to itself over and over until it makes sense

EX: T(n) = 4T(n/2) + 1
Smack it onto itself
T(n) = 16T(n/4) + 2 + 1
Note: The +2 is because by smacking it onto itself it actually means placing T(n) into the place of n and we need to multiply 1 by 2 to get it out of the /2 area
See that after infinity steps the problem size becomes n/$2^k$ so the final time complexity is log(n)
EX 2: T(n) = T(n/2) + n
Smack it onto itself
T(n) = T(n/4) + 3n
we can see that the problem size becomes n/$2^k$ when taken to infinity but since we have the value of n in there we need to say that the time complexity is nlog(n)

NOTE: Understanding the algorithm is key to understanding how to backwards sub it and what the final time complexity should be
* How to perform different sorting algorithms, Selection Sort, Bubble Sort, Quick Sort, Merge Sort
-__Selection Sort__ $\rightarrow$ Finds the minimum value in an array and swaps it with the first unsorted element EX: 3,5,8,2 $\rightarrow$ the minimum element is 2 so it will be swapped with 3 then the algorithm will continue
-__Bubble Sort__ $\rightarrow$ compares two elements, if the one in front of it is the first element is less, then it swaps them, think of it like grabbing the greater of the two values it is comparing and shoving it backwards until the greatest one hits the end
-__Quick Sort__ $\rightarrow$ Selects a pivot (typically the last element in the array/subarray) then compares it to everything in the list, placing those things on the left or the right if they are less or greater than the value. Then it recurses on the two subarrays on each side, performing the same thing
-__Merge Sort__ $\rightarrow$ Splits the array in half recursively until each sub array has a size of one, then it begins merging them, comparing along the way until it is all sorted


* Knapsack problem, traveling salesman
-Knapsack problem solution: recursively try every possible combination, finally returning the greatest value that is still within the weight limit
-Traveling salesman problem solution- Depends on if the shortest path is acceptable 
If acceptable pick the shortest option out of the paths to nodes you haven't yet gone to in a depth first search style
If unacceptable simply preform a DFS

* __KNOW HOW TO DO ADJACENCY MATRIX AND ADJACENCY LIST THINGS__ $\leftarrow$ Very Important
-See above

* Divide and Conquer strategy __There may be a problem where we have to give the pseudocode for a algorithm that does something divide and Conquer and a brute force version of that algorithm

* Binary Tree Traversal Problems
-Pre-Order- Root,Left,Right, In-Order-left,root,right, and Post-Order-left,right,root

* __Understand how merge sort and quick sort work__ $\leftarrow$ algorithms will be given in exam: Draw a diagram to show how it works
-See above, with quicksort make sure to show the location of i and j

* Decrease and Conquer strategy, such as insertion sort
-Remember that with insertion sort once the minimum element is in place at the start of the array we don't need to worry about it and don't need to compare things to it

* Know how to go from directed graph to adjacency matrix and adjacency list
-See above

* __Know how to do topological sort__ 
-start at nodes that don't have any incoming paths and work down removing nodes as you go, must be a `DAG`


* Do the binary search of a given list
-Go to the middle of a list, compare the element to that and either go to the left or right sublist if the element is less or greather than the middle value, it it is equal return that value

* Selection problem $\leftarrow$ Quick select
-A lot like quicksort, take a pivot (typically the last element in an array) and place everything on the left or the right of it, if your element is less than the pivot then go left, otherwise go right
-Mostly used to find things like the third largest value in a list

* Find the median of an array
-Sort array, if odd the medians position is at $(n+1)/2$ if even it is the average of the values at $n/2 $and $(n+1)/2$

* Transform and conquer instance simplification ex: presorting

* Mode calculation
-Presort the list, while a number = the current mode add to the currentCount value, if once the number is no longer equal to the previous mode value and the currentCount is greater than the previous mode, change the previous mode accordingly
-Key Takaway- For loop and nested while loop

* __AVL tree and how to build them/do rotations on them__
-Very simple, look at slides if need be

* 2-3 Trees and how to build them -remember that when the bubble gets three numbers it pops

* __NO B-Trees will be on the exam__

* Bottom up and top down construction of a heap
-Bottom Up - Insert each element into the tree ignoring its proper placement, then once everything is in place compare them to their parent, if it is greater than the parent then swap them
-Top down- Insert three elements, if one of them is out of place then switch them (heapify), continue like this swapping as soon as there is an issue instead of causing a ton of problems like in bottom up then fixing them all at once


